{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "#hllDll = ctypes.WinDLL(\"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.1\\\\bin\\\\cudart64_101.dll\")\n",
    "#incase cudart64_101.dll is unable to be loaded\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "from medpy.io import load\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from tensorflow.keras import layers\n",
    "#import keras\n",
    "import sklearn\n",
    "from scipy.ndimage import rotate\n",
    "import scipy\n",
    "import time\n",
    "from sklearn import datasets, preprocessing, model_selection, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(level = 'logging.INFO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15428671211691862370\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15278828619054665779\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3057018470\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16121076866482762412\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15182840219776266020\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "'''Confirming running on GPU'''\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "CUDA_VISIBLE_DEVICES = 0,1\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Predetermined Functions'''\n",
    "def Generic_image_generator(URL):\n",
    "    image_data, image_header = load(URL)\n",
    "    for iter in range(0,len(image_data[:][:])):\n",
    "        yield image_data[iter]\n",
    "\n",
    "def create_ID_dict(basepath): #currently only set to return CT and segmentation mask images, not CTA's\n",
    "    '''basepath is location of file that is holding dataset, datasets should be deeper in the file tree'''\n",
    "    logging.info(\"creating dataset location directory/dictionary from {}\".format(basepath))\n",
    "    dict = {}\n",
    "    mask_list = []\n",
    "    image_list = []\n",
    "    for root, dirs, list_of_files in os.walk(basepath):\n",
    "        for files in list_of_files:\n",
    "            if \"r.mhd\" in files:\n",
    "                mask_list.append(os.path.join(root,files))\n",
    "            else: \n",
    "                pass\n",
    "            \n",
    "            if \"cti.mhd\" in files:\n",
    "                image_list.append(os.path.join(root,files))\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "    dict.update({\"image\" : image_list })\n",
    "    dict.update({\"mask\" : mask_list })\n",
    "    logging.info(\"dictionary created\")\n",
    "    \n",
    "    return dict\n",
    "\n",
    "def image_preprocessing(array):\n",
    "    logging.info(\"Beginning Preprocessing\")\n",
    "    \n",
    "    logging.info(\"Rotating Image into axial plane\")\n",
    "    array = rotate(array, 90, axes=(0,2), reshape=True) #rotates to axial form sup to inf\n",
    "    \n",
    "    logging.info(\"Making image to uniform size\")\n",
    "    \n",
    "    blank_array = np.full((1,512,512),-3024) #-3024 is the \"background, out of zoom data point\"\n",
    "    \n",
    "    while len(array) < 69:\n",
    "        array = np.append(array, blank_array, axis = 0)\n",
    "        array = np.append(blank_array, array, axis = 0)\n",
    "        \n",
    "    if len(array) == 69:\n",
    "        array = np.append(array,blank_array, axis = 0)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    logging.info(\"Image Preprocessing is complete\")\n",
    "    \n",
    "    return array\n",
    "    \n",
    "def image_generator(dict_obj, mask):\n",
    "    \n",
    "    generate_mask = False\n",
    "    logging.info(\"creating image generator for {}. Images are Segmentation Masks? = {}.\".format(dict_obj,mask))\n",
    "    \n",
    "    if mask == True:\n",
    "        generate_mask = True\n",
    "    \n",
    "    if generate_mask == True:\n",
    "        for path in dict_obj['mask']:\n",
    "            logging.info(\"loading {} {} into generator\".format(\"mask\",os.path.basename(path)))\n",
    "            image, header = load(path)\n",
    "            image = image_preprocessing(image)\n",
    "            logging.info(\"Generator created\")\n",
    "            yield image, header\n",
    "            \n",
    "    elif generate_mask == False:\n",
    "        for path in dict_obj[\"image\"]:\n",
    "            logging.info(\"loading {} {} into generator\".format(\"image\",os.path.basename(path)))\n",
    "            image, header  = load(path)\n",
    "            image = image_preprocessing(image)\n",
    "            logging.info(\"Generator created\")\n",
    "            yield image, header\n",
    "    else:\n",
    "        raise TypeError(\"Problem with inputs.\")\n",
    "        logging.error(\"Unable to load image into generator\")\n",
    "            \n",
    "    #no normalization has been added yet. Will need to think about how I want to approach this.\n",
    "    #from skimage.color import rgb2gray to make things grayscale.\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_slice_generator(generator, batchsize=5):\n",
    "    while True:\n",
    "        batch_img= []\n",
    "        \n",
    "        for img in generator:\n",
    "            for slice in img:\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Need to do\"\"\"\n",
    "'''\n",
    "- Do I need to make a second generator for batch size? (https://www.kaggle.com/abhmul/python-image-generator-tutorial) \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Predetermined Variables'''\n",
    "PATH_tr = 'C:\\\\Users\\\\Andrew_Arbogast\\\\Desktop\\\\Codes\\\\UCAIDM\\\\CAIDM Project\\\\DataSets\\\\orCAScore Dataset\\\\Filtered\\\\Training_Set\\\\Train\\\\'\n",
    "PATH_val = 'C:\\\\Users\\\\Andrew_Arbogast\\\\Desktop\\\\Codes\\\\UCAIDM\\\\CAIDM Project\\\\DataSets\\\\orCAScore Dataset\\\\Filtered\\\\Training_Set\\\\Validation\\\\'\n",
    "PATH_te = 'C:\\\\Users\\\\Andrew_Arbogast\\\\Desktop\\\\Codes\\\\UCAIDM\\\\CAIDM Project\\\\DataSets\\\\orCAScore Dataset\\\\Filtered\\\\Testing_Set\\\\'\n",
    "Model_path = 'C:\\\\Users\\\\Andrew_Arbogast\\\\Desktop\\\\Codes\\\\UCAIDM\\\\CAIDM Project\\\\Coronary_Calcium\\\\Models\\\\'\n",
    "model_vers = 'First_Attempt'\n",
    "input_shape = (70,512,512,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Creation Took 0.009000778198242188 seconds\n",
      "Generators Creation Took 0.0 sec\n"
     ]
    }
   ],
   "source": [
    "''' Loading Data Sets '''\n",
    "logging.info(\"loading datasets\")\n",
    "\n",
    "start_time = time.time()\n",
    "tr_dict = create_ID_dict(PATH_tr)\n",
    "val_dict = create_ID_dict(PATH_val)\n",
    "te_dict = create_ID_dict(PATH_te)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Dictionary Creation Took {} seconds\".format(end_time-start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "tr_img = image_generator(tr_dict,mask = False)\n",
    "tr_mask = image_generator(tr_dict, mask = True)\n",
    "val_img = image_generator(val_dict, mask = False)\n",
    "val_mask = image_generator(val_dict, mask = True)\n",
    "te_img = image_generator(te_dict, mask = False)\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print(\"Generators Creation Took {} sec\".format(end_time-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating NN'''\n",
    "\n",
    "\n",
    "if os.path.isdir(Model_path+model_vers)==True:\n",
    "    logging.info(\"Loading Network\")\n",
    "    model=tfk.models.load_model(\"Model_path+model_vers\")\n",
    "    \n",
    "else:\n",
    "    logging.info(\"Creating Network\")\n",
    "#https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130    \n",
    "    model= tfk.Sequential()\n",
    "    model.add(layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "    model.add(layers.BatchNormalization(center=True, scale=True))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "    model.add(layers.BatchNormalization(center=True, scale=True))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(layers.Dense(15, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "'''Hyper Parameters'''\n",
    "logging.info(\"Adding Hyperparameters\")\n",
    "\n",
    "optimizer=tfk.optimizers.Adadelta()\n",
    "loss=\"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer = optimizer, loss= loss, metrics= metrics )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Other, Not in Use Model attempts\"\"\"\n",
    "\n",
    "   \n",
    "''' For a 2D network'''\n",
    "\"\"\"model= tfk.Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=3, stride=(1,1), activation=’relu’, input_shape=(28,28,1)))\n",
    "    model.add(Conv2D(32, kernel_size=3,stride=(1,1), activation=’relu’))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation=’softmax’))\"\"\"\n",
    "''' For a 3D network'''\n",
    "    #tf.keras.layers.Conv3D(filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None,\n",
    "    #dilation_rate=(1, 1, 1), activation=None, use_bias=True,\n",
    "    #kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    #kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    #kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    "'''\n",
    "model= tfk.Sequential()\n",
    "input_shape = (70,512,512,1)\n",
    "model.add(layers.Conv3D(filters=64, kernel_size=3,strides=(1, 1, 1), activation='relu', input_shape=input_shape))\n",
    "model.add(layers.Conv3D(filters=32, kernel_size=3,strides=(1, 1, 1), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='softmax'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using python generator as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bc3b11bf963e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#model.save(\"First_Attempt_Model/Model\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrew_arbogast\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrew_arbogast\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m           model=self)\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrew_arbogast\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrew_arbogast\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m       raise ValueError(\"`y` argument is not supported when using \"\n\u001b[0m\u001b[0;32m    763\u001b[0m                        \"python generator as input.\")\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `y` argument is not supported when using python generator as input."
     ]
    }
   ],
   "source": [
    "\"\"\"Training NN\"\"\"\n",
    "logging.info(\"Training Neural Network\")\n",
    "model.fit(\n",
    "    tr_img, tr_mask, \n",
    "    batch_size=1, \n",
    "    epochs = 10,\n",
    "    verbose=2\n",
    ")\n",
    "#model.save(\"First_Attempt_Model/Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
